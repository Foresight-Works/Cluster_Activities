{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './data/experiments'\n",
    "data_files = [' '] + os.listdir(data_dir)\n",
    "#if 'message.npy' in os.listdir():\n",
    "#    os.remove('message.npy')\n",
    "\n",
    "# Widget styles\n",
    "default = (data_files[0], ' ')\n",
    "style = {'description_width': 'initial'}\n",
    "features_layout = {'width': 'max-content','height':'200px'}\n",
    "\n",
    "from IPython.display import display, HTML, clear_output, display_html\n",
    "from itertools import chain,cycle\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, Layout, HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', 100)\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import ast\n",
    "import mysql.connector as mysql\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# File selection menu\n",
    "file_dd=widgets.SelectMultiple(options=data_files,value=default,\n",
    "    description='File:',style=style,layout=features_layout)\n",
    "# Service \n",
    "service_button = widgets.RadioButtons(\n",
    "    options=['Local', 'Remote'], value='Local',layout={'width': 'max-content'}, description='Service:',\n",
    "    disabled=False)\n",
    "# Analyse button \n",
    "run_button = widgets.Button(description = \"Cluster\",style=style)\n",
    "run_button.style.button_color = 'lightgreen'\n",
    "# Metric menues\n",
    "metrics_layout = {'display':'flex','width': '130px','height':'30px', 'justify_content':'flex-end'}\n",
    "options = list(np.arange(1,11))\n",
    "options = [str(o) for o in options]\n",
    "metrics_optimize = {'min_max_tpc': ('min', 1), 'wcss': ('min', 1), 'bcss': ('max', 1), 'ch_index': ('max', 1),\\\n",
    "'db_index':('min', 1), 'silhouette':('max', 1), 'words_pairs': ('max', 1)}\n",
    "metrics = list(metrics_optimize.keys())\n",
    "metrics_menues = {}\n",
    "for metric in metrics:\n",
    "    menue=widgets.Dropdown(options=options,value='1',description=metric, layout=metrics_layout)\n",
    "    metrics_menues[metric]=menue\n",
    "# Granularity slider\n",
    "granularity = widgets.IntSlider(value=100, min=2, max=1000, step=1, description='Number of Clusters',\\\n",
    "                                     orientation='horizontal',readout=True, readout_format='d',\\\n",
    "                                     style = {'description_width': 'initial'}, layout=Layout(width='400px'))\n",
    "apply_granularity = widgets.ToggleButton(value=False, description='Select granularity level?',\n",
    "    disabled=False, button_style='info', tooltip='Description',\n",
    "    icon='check', layout=Layout(width='200px'))\n",
    "# Minimal cluster size\n",
    "min_cluster_menue=widgets.Dropdown(options=['0']+ options,value='0',\\\n",
    "                       description='Minimum number of tasks in cluster',\\\n",
    "                                   style = {'description_width': 'initial'},\\\n",
    "                                   layout=Layout(width='300px'))\n",
    "\n",
    "# Service    \n",
    "service_location =  'Remote' # 'Local'\n",
    "metrics_optimize = {'min_max_tpc': ('min', 1), 'wcss': ('min', 1), 'bcss': ('max', 1), 'ch_index': ('max', 1),\\\n",
    "'db_index':('min', 1), 'silhouette':('max', 1), 'words_pairs': ('max', 1)}\n",
    "db_name = 'CAdb'\n",
    "location_db_params = {'Local': {'host': 'localhost', 'user':'rony', 'password':'exp8546$fs', 'database': db_name},\\\n",
    "                      'Remote': {'host': '172.31.36.11', 'user':'researchUIuser', 'password':'query1234$fs', 'database': db_name}}\n",
    "conn_params = location_db_params[service_location]\n",
    "conn = mysql.connect(**conn_params)\n",
    "c=conn.cursor()\n",
    "c.execute(\"SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED\")\n",
    "location_url = {'Local': 'http://127.0.0.01:6002/cluster_analysis/api/v0.1/clustering',\\\n",
    "                'Remote': 'http://172.31.36.11/cluster_analysis/api/v0.1/clustering'}\n",
    "url = location_url[service_location]\n",
    "\n",
    "matrices_dir = '/home/rony/Projects_Code/Cluster_Activities/matrices'\n",
    "distance_matrices = []\n",
    "matrices = os.listdir(matrices_dir)\n",
    "for matrix in matrices:\n",
    "    path = os.path.join(matrices_dir, matrix)\n",
    "    distance_matrices.append(pd.read_pickle(path))\n",
    "\n",
    "punctuation_marks=\"=|\\+|_|\\.|:|\\/|\\*|\\'|,|?\"\n",
    "def split_tokens (tokens, splitter):\n",
    "    tokens_splitter= [t for t in tokens if splitter in t]\n",
    "    tokens = [t for t in tokens if splitter not in t]\n",
    "    for t in tokens_splitter: tokens += t.split(splitter)\n",
    "    return tokens\n",
    "\n",
    "def isfloat(value):\n",
    "    '''\n",
    "    Check if the input value type is float\n",
    "    '''\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def isint(value):\n",
    "    '''\n",
    "    Check if the input value type is integer\n",
    "    '''\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def tokenize(data, unique=True, is_list=False,\\\n",
    "              exclude_parenthesis_terms=False, exclude_stopwords=False, exclude_chars=True,\\\n",
    "              split_backslah=True, split_hyphen=True, split_plus=True, \\\n",
    "              clean_punctuation=False, exclude_numbers=False, exclude_digit_tokens=False, \\\n",
    "              punctuation_symbols=punctuation_marks, stopwords=set(stopwords.words('english'))):\n",
    "\n",
    "    if is_list:\n",
    "        data = [t for t in data if type(t)==str]\n",
    "        data = ' '.join(data)\n",
    "        data = re.sub('\\s{2,}', ' ', data)\n",
    "\n",
    "    if exclude_parenthesis_terms:\n",
    "        pattern= '\\(.+?\\)|\\w*\\d{1,}\\.*\\d{1,}\\w*|\\w+'\n",
    "        data= re.sub(data, '', pattern)\n",
    "\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    if split_backslah: tokens = split_tokens (tokens, '/')\n",
    "    if split_hyphen: tokens = split_tokens(tokens, '-')\n",
    "    if split_plus: tokens = split_tokens(tokens, '+')\n",
    "\n",
    "    if exclude_stopwords: tokens = [t for t in tokens if t not in stopwords]\n",
    "    if clean_punctuation: tokens = [re.sub(punctuation_symbols, '', t) for t in tokens]\n",
    "    if exclude_chars:tokens = [t for t in tokens if len(t) > 1]\n",
    "    if exclude_numbers:\n",
    "        tokens = [t for t in tokens if (not(isint(t)))]\n",
    "        tokens = [t for t in tokens if (not(isfloat(t)))]\n",
    "    if exclude_digit_tokens:tokens = [t for t in tokens if not re.findall('\\d', t)]\n",
    "\n",
    "    if unique: tokens = list(set(tokens))\n",
    "    return tokens\n",
    "\n",
    "def tokens_count(tokens):\n",
    "    counts = dict()\n",
    "    for token in tokens:\n",
    "        if token in counts:\n",
    "            counts[token] += 1\n",
    "        else:\n",
    "            counts[token] = 1\n",
    "    return counts\n",
    "\n",
    "def get_cluster_key(cluster_names, cutoff=0.8):\n",
    "    names_tokens = {}\n",
    "    for name in cluster_names:\n",
    "        tokens = tokenize(name, unique=True, exclude_stopwords=True, \\\n",
    "                           exclude_numbers=True, exclude_digit_tokens=True)\n",
    "        names_tokens[name] = tokens\n",
    "\n",
    "    cluster_names_pairs = tuple(combinations(cluster_names, 2))\n",
    "    pairs_matches = []\n",
    "    for name_pair in cluster_names_pairs:\n",
    "        name1, name2 = name_pair\n",
    "        tokens1, tokens2 = names_tokens[name1], names_tokens[name2]\n",
    "        tokens1 = [t.lower() for t in tokens1]\n",
    "        tokens2 = [t.lower() for t in tokens2]\n",
    "        if name1 == name2:\n",
    "            pair_matches = tokens1\n",
    "        else:\n",
    "            len1, len2 = len(tokens1), len(tokens2)\n",
    "            if len1 <= len2:\n",
    "                short_name_tokens, long_name_tokens = tokens1, tokens2\n",
    "            else: short_name_tokens, long_name_tokens = tokens2, tokens1\n",
    "            pair_matches = []\n",
    "            for short_name_token in short_name_tokens:\n",
    "                short_name_token = [short_name_token]\n",
    "                names_token_pairs = list(itertools.product(short_name_token, long_name_tokens))\n",
    "                token_pairs_scores = {}\n",
    "                for tokens_pair in names_token_pairs:\n",
    "                    # Use distance matrices to score token pairs\n",
    "                    token1, token2 = tokens_pair\n",
    "                    token_pairs_score = 0\n",
    "                    for index, matrix in enumerate(distance_matrices):\n",
    "                        if all(x in matrix.columns for x in tokens_pair):\n",
    "                            matrix_score = matrix.at[token1, token2]\n",
    "                        else: matrix_score = 0\n",
    "                        token_pairs_score += matrix_score\n",
    "                    token_pairs_score = round(token_pairs_score, 2)\n",
    "                    token_pairs_scores[tokens_pair] = token_pairs_score\n",
    "\n",
    "                # Identify the best match in the long name to the short name token\n",
    "                max_score = max(list(token_pairs_scores.values()))\n",
    "                if max_score >= cutoff:\n",
    "                    for tokens_pair, pair_score in token_pairs_scores.items():\n",
    "                        if pair_score == max_score: matched_token = tokens_pair[1]\n",
    "                    #print('matched token with best score:', matched_token)\n",
    "                    pair_matches.append(matched_token)\n",
    "\n",
    "        pairs_matches.append(tuple(pair_matches))\n",
    "    matches_tokens = []\n",
    "    for pair_matches in pairs_matches: matches_tokens += list(pair_matches)\n",
    "    matches_tokens_counts = tokens_count(matches_tokens)\n",
    "\n",
    "    # Score each match by the frequency of its tokens\n",
    "    match_scores = {}\n",
    "    for pair_matches in pairs_matches:\n",
    "        match_score = 0\n",
    "        for token in pair_matches:\n",
    "            match_score += matches_tokens_counts[token]\n",
    "        match_scores[pair_matches] = match_score\n",
    "\n",
    "    # Score each match by it's length in relation to the names lengths\n",
    "    names = []\n",
    "    for name_pair in cluster_names_pairs: names += name_pair\n",
    "    names_lengths_median = np.median(np.array([len(name) for name in names]))\n",
    "    for pair_matches in pairs_matches:\n",
    "        near_median_factor = len(pair_matches)/names_lengths_median\n",
    "        match_scores[pair_matches] = near_median_factor * match_scores[pair_matches]\n",
    "\n",
    "    # Identify the best scoring match\n",
    "    max_score = max(list(match_scores.values()))\n",
    "    for pair_matches, match_score in match_scores.items():\n",
    "        if match_score == max_score:\n",
    "            cluster_key = pair_matches\n",
    "\n",
    "    cluster_key = ' '.join(list(set(cluster_key)))\n",
    "    return cluster_key\n",
    "\n",
    "\n",
    "\n",
    "def run_service(b):\n",
    "    file_checkpoints = True\n",
    "    ## Submitted data files\n",
    "    files = file_dd.value\n",
    "    print('files:', files)\n",
    "    file_types = list(set([t.split('.')[1] for t in files]))\n",
    "    print('file types:', file_types)\n",
    "    #Checkpoint: Files submitted\n",
    "    if files[0][0] == ' ':\n",
    "        print('No file selected')\n",
    "        file_checkpoints = False\n",
    "    #Checkpoint: Zip files\n",
    "    elif 'zip' in file_types:\n",
    "        #Checkpoint: One among few files zipped \n",
    "        if len(file_types)>1: \n",
    "            print('The submitted files include a zip file')\n",
    "            file_checkpoints = False\n",
    "        else: \n",
    "            data_path = os.path.join(data_dir, files[0])\n",
    "            files = {'file': open(data_path, 'rb')} \n",
    "    #Zip data files \n",
    "    else:\n",
    "        file_paths = []\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(data_dir, file))\n",
    "        print('file_paths:', file_paths)\n",
    "        with ZipFile('zipped_files.zip','w') as zip:\n",
    "            # writing each file one by one\n",
    "            for file_path in file_paths:\n",
    "                zip.write(file_path)\n",
    "        files = {'file': open('zipped_files.zip', 'rb')}\n",
    "        os.remove('zipped_files.zip')\n",
    "    \n",
    "    if file_checkpoints:\n",
    "        ## Experiment configuration\n",
    "        config = {}\n",
    "        \n",
    "        # Experiment id\n",
    "        experiment_ids = pd.read_sql_query(\"SELECT experiment_id from results\", conn).astype(int)\n",
    "        if len(experiment_ids) == 0: experiment_id = 1\n",
    "        else: experiment_id = int(max(experiment_ids.values)[0]) + 1\n",
    "\n",
    "        config['experiment_id'] = experiment_id\n",
    "        print('experiment_id:', experiment_id)\n",
    "        \n",
    "        min_cluster_size = min_cluster_menue.value[0]\n",
    "        print('min_cluster_size:', min_cluster_size)\n",
    "        config['min_cluster_size'] = min_cluster_size\n",
    "\n",
    "        # Metrics weights\n",
    "        for metric, menue in metrics_menues.items():\n",
    "            config[metric] = menue.value[0]\n",
    "        if apply_granularity.value:\n",
    "            config['num_clusters'] = granularity.value\n",
    "        \n",
    "        # Post experiment data and configuration\n",
    "        response = requests.post(url, files=files, data=config)\n",
    "        print(response.text)\n",
    "        if response.text == 'Activity names clustered':\n",
    "            \n",
    "            # Show runs results\n",
    "            display(HTML('<h1 style=\"color:magenta\">Run Scores </h1>'))\n",
    "            print('Run for experiment {eid}'.format(eid=experiment_id))\n",
    "            run_cols = ['run_start', 'run_end', 'duration', 'tasks_count']\n",
    "            runs_df = pd.read_sql_query(\"SELECT * FROM runs \\\n",
    "            WHERE experiment_id={eid}\".format(eid=experiment_id), conn).drop(run_cols, axis=1)\n",
    "            display(runs_df)\n",
    "            \n",
    "            # Present the best run result\n",
    "            print('Experiment results')\n",
    "            result_df = pd.read_sql_query(\"SELECT * FROM results \\\n",
    "            WHERE experiment_id={eid}\".format(eid=experiment_id), conn).drop(run_cols, axis=1)\n",
    "            best_run_id = result_df['run_id'].values[0]\n",
    "            print('Run id for the best run=', best_run_id)\n",
    "            print('The clusters for the best run are ready for drill down analysis')\n",
    "            result = result_df['result'].values[0]\n",
    "            \n",
    "def get_activities(b):\n",
    "    #clear_output()\n",
    "    cluster_key = clusters_keys_dd.value\n",
    "    result = pd.read_sql_query(\"SELECT Result FROM results\", conn).values[0][0]\n",
    "    result_dict = ast.literal_eval(result)\n",
    "    clusters = list(ast.literal_eval(result).values())[0]\n",
    "    ids_names = clusters[cluster_key]\n",
    "    ids_names = [' '.join(id_name) for id_name in ids_names]\n",
    "    ids_names = '\\n'.join(ids_names)\n",
    "    with open('ids_names.txt', 'w') as f: f.write(ids_names)\n",
    "        \n",
    "def cluster_stats_plots(b):\n",
    "    #clear_output()\n",
    "    cluster_key = clusters_keys_dd.value\n",
    "    names_to_exclude = ids_names_dd.value\n",
    "    exclude_ids = [i.split(' ')[0] for i in names_to_exclude]\n",
    "    result = pd.read_sql_query(\"SELECT Result FROM results\", conn).values[0][0]\n",
    "    result_dict = ast.literal_eval(result)\n",
    "    clusters = list(ast.literal_eval(result).values())[0]\n",
    "    # Activities duration values\n",
    "    ids_names = {i[0]:i[1] for i in clusters[cluster_key] if i[0] not in exclude_ids}\n",
    "    ids, names = list(ids_names.keys()), list(ids_names.values())\n",
    "    new_key = get_cluster_key(names, cutoff=0.8)\n",
    "    \n",
    "    planned_duration_dict = result_dict['planned_duration_vals']\n",
    "    #print('planned_duration_dict:', planned_duration_dict)\n",
    "    planned_duration_dict = {k:v for k,v in planned_duration_dict.items() if k in ids}\n",
    "    #print('planned_duration_dict:', planned_duration_dict)\n",
    "    planned_duration_vals = list(planned_duration_dict.values())\n",
    "    #print('planned_duration_vals:', planned_duration_vals)\n",
    "\n",
    "    actual_duration_dict = result_dict['actual_duration_vals']\n",
    "    actual_duration_dict = {k:v for k,v in actual_duration_dict.items() if k in ids}\n",
    "    #print('actual_duration_dict:', actual_duration_dict)\n",
    "    actual_duration_vals = list(actual_duration_dict.values())\n",
    "    #print('actual_duration_vals:', actual_duration_vals)\n",
    "\n",
    "    planned_in_actual_dict = {k:v for k,v in planned_duration_dict.items() if k in actual_duration_dict.keys()}\n",
    "    #print('planned_in_actual_dict:', planned_in_actual_dict)\n",
    "\n",
    "    # Duration ratios and overruns\n",
    "    duration_ratios, tasks_overrun, tasks_overrun_perc = [], [], []\n",
    "    for id, task_planned_duration in planned_in_actual_dict.items():\n",
    "        task_actual_duration = actual_duration_dict[id]\n",
    "        if task_planned_duration != 0:\n",
    "            duration_ratios.append(round(task_actual_duration/task_planned_duration,2))\n",
    "            task_overrun = task_actual_duration-task_planned_duration\n",
    "            tasks_overrun.append(task_overrun)\n",
    "            tasks_overrun_perc.append(task_overrun/task_planned_duration)\n",
    "\n",
    "    ## Cluster Statistics\n",
    "    display(HTML('<h1 style=\"color:magenta\">Cluster RCF Analysis</h1>'))\n",
    "    print('New Key:', new_key)\n",
    "    print('Cluster Statistics')\n",
    "    print('Activities in Cluster:', len(ids))\n",
    "    print('Completed Activities in Cluster:', len(actual_duration_vals))\n",
    "    # Table\n",
    "    index = ['Planned Duration(Days)', 'Actual Duration(Days)', 'Overrun(Days)', 'Overrun(%)']\n",
    "    headers = ['MEAN', 'MEDIAN', 'STD']\n",
    "    def stats_row(arr): \n",
    "        if len(arr)>0:\n",
    "            return [np.mean(arr), np.median(arr), np.std(arr)]\n",
    "        else:\n",
    "            return(np.nan, np.nan, np.nan)\n",
    "    table_rows = [stats_row(planned_duration_vals), stats_row(actual_duration_vals),\\\n",
    "                 stats_row(tasks_overrun), stats_row(tasks_overrun_perc)]\n",
    "    stats_df = pd.DataFrame(table_rows, columns=headers, index=index)\n",
    "    stats_df = round(stats_df, 2)\n",
    "    #display(stats_df)                \n",
    "\n",
    "    # Plot Values: RCF for Tasks in Cluster\n",
    "    # x = percentile,  y = duration_ratios\n",
    "    duration_ratios.sort()\n",
    "    sum_ratios = sum(duration_ratios)\n",
    "    ratios_cumsum = np.cumsum(duration_ratios)\n",
    "    percentile = 100*(ratios_cumsum/sum_ratios)\n",
    "    rcf_df = pd.DataFrame(list(zip(percentile, duration_ratios)),\\\n",
    "                          columns = ['Percentile', 'Duration Ratio'])\n",
    "\n",
    "    # Plot Values: Duration Distribution\n",
    "    duration_type = len(planned_duration_vals) * ['Planned'] + len(actual_duration_vals) *['Actual']\n",
    "    duration_vals = list(planned_duration_vals)+list(actual_duration_vals)\n",
    "    duration_df = pd.DataFrame(list(zip(duration_type, duration_vals)), columns=['Duration', 'Days'])\n",
    "\n",
    "    # Cluster description\n",
    "    names_df = pd.DataFrame(ids, columns=['ID'])\n",
    "    names_df['Name'] = names\n",
    "    names_df['Planned Duration'] = planned_duration_vals\n",
    "    names_df['Actual Duration'] = actual_duration_vals\n",
    "\n",
    "    ## Display\n",
    "    # Tables\n",
    "    display_side_by_side(names_df,stats_df, titles=['Tasks in Cluster','Cluster Statistics'])\n",
    "\n",
    "    # Plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))#, sharey=True)\n",
    "    duration_dist = sns.boxplot(ax=axes[0], x=\"Duration\", y=\"Days\", data=duration_df)\n",
    "    rcf = sns.lineplot(ax=axes[1], x=\"Percentile\", y=\"Duration Ratio\", data=rcf_df)\n",
    "    axes[0].set_title('Duration Distibution (Tasks in Cluster)')\n",
    "    axes[1].set_title('RCF For Tasks in Cluster')\n",
    "    \n",
    "def left_align(df):\n",
    "    left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "    left_aligned_df = left_aligned_df.set_table_styles(\n",
    "        [dict(selector='th', props=[('text-align', 'left')])]\n",
    "    )\n",
    "    return left_aligned_df\n",
    "\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:right\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h2>{title}</h2>'\n",
    "        df=left_align(df)\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "def get_clusters(b):\n",
    "    experiment_id = experiments_dd.value\n",
    "    result_df = pd.read_sql_query(\"SELECT * FROM results \\\n",
    "    WHERE experiment_id={eid}\".format(eid=experiment_id), conn)\n",
    "    best_run_id = result_df['run_id'].values[0]\n",
    "    result = pd.read_sql_query(\"SELECT Result FROM results\", conn).values[0][0]\n",
    "    clusters = list(ast.literal_eval(result).values())[0]\n",
    "    clusters_keys = list(clusters.keys())\n",
    "    clusters_keys = '\\n'.join(clusters_keys)\n",
    "    with open('clusters_keys.txt', 'w') as f: f.write(clusters_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Cluster Activities</h1>              <p style=\"color:blue\">Use to following menus to submit a file for analysis:</p>                 <ul>                  <li style=\"color:magenta\">File to analyze</li>                  <li style=\"color:magenta\">Select granularity level</li>                  <li style=\"color:magenta\">Set weights for validation metrics</li>                </ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1c6edf15814773a4e13a7f88a38fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(RadioButtons(description='Service:', layout=Layout(width='max-content'), options…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ('CCGTD1_IPS_sample.zip',)\n",
      "file types: ['zip']\n",
      "experiment_id: 1\n",
      "min_cluster_size: 0\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dashboard\n",
    "run_button.on_click(run_service)\n",
    "display(HTML('<h1 style=\"color:magenta\">Cluster Activities</h1>\\\n",
    "              <p style=\"color:blue\">Use to following menus to submit a file for analysis:</p>\\\n",
    "                 <ul>\\\n",
    "                  <li style=\"color:magenta\">File to analyze</li>\\\n",
    "                  <li style=\"color:magenta\">Select granularity level</li>\\\n",
    "                  <li style=\"color:magenta\">Set weights for validation metrics</li>\\\n",
    "                </ul>'))\n",
    "file_box = VBox(children=[service_button, file_dd, run_button])\n",
    "metrics_box = VBox(children=list(metrics_menues.values()))\n",
    "config_box = VBox(children=[apply_granularity, granularity, min_cluster_menue])\n",
    "HBox(children=[file_box, config_box, metrics_box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment and Run Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Select Experiment and Run </h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54afb1153c3a45afa275485a16df4922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Select Experiment:', layout=Layout(width='max-content'), options=(2, 3, 4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h1 style=\"color:magenta\">Select Experiment and Run </h1>'))\n",
    "experiment_ids = pd.read_sql_query(\"SELECT experiment_id FROM results\", conn).astype(int)\n",
    "experiment_ids = list(experiment_ids['experiment_id'].unique())\n",
    "experiments_dd=widgets.Dropdown(options=experiment_ids, value=experiment_ids[0],\n",
    "    description='Select Experiment:',style=style, layout={'width': 'max-content'})\n",
    "clusters_button = widgets.Button(description = \"Clusters \",style=style, layout={'width': 'max-content'})\n",
    "clusters_button.style.button_color = 'lightblue'\n",
    "clusters_button.on_click(get_clusters)\n",
    "HBox(children=[experiments_dd, clusters_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef559b2ecea4a818ddf63bbad93cc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Select Cluster:', layout=Layout(width='max-content'), options=('nde', 'te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusters_keys = open('clusters_keys.txt').read().split('\\n')\n",
    "clusters_keys_dd=widgets.Dropdown(options=clusters_keys, value=clusters_keys[0],\n",
    "    description='Select Cluster:',style=style, layout={'width': 'max-content'})\n",
    "button = widgets.Button(description = \"Get Tasks\",style=style)\n",
    "button.style.button_color = 'orange'\n",
    "button.on_click(get_activities)\n",
    "HBox(children=[clusters_keys_dd, button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94998cf8b27f469ca351ba112752b5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Names to exclude:', index=(0, 0), layout=Layout(display='flex', fle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids_names = [' '] + open('ids_names.txt').read().split('\\n')\n",
    "#ids_names = [(id_name,) for id_name in ids_names]\n",
    "layout={'width': 'max-content', 'height':'max-content'}\n",
    "layout=Layout(display=\"flex\", flex_flow='column')\n",
    "ids_names_dd=widgets.SelectMultiple(options=ids_names, value=(ids_names[0], ' '),\n",
    "    description='Names to exclude:',style=style, layout=layout)\n",
    "button = widgets.Button(description = \"Run RCF\",style=style)\n",
    "button.style.button_color = 'yellow'\n",
    "button.on_click(cluster_stats_plots)\n",
    "HBox(children=[ids_names_dd, button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
