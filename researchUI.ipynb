{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mysql-connector-python\n",
    "#!pip install ipywidgets==7.6.0\n",
    "#!pip install nltk\n",
    "#!pip install boto3\n",
    "#!pip install pika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import display, HTML, clear_output, display_html\n",
    "from itertools import chain,cycle\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, Layout, HBox, VBox\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', 100)\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import ast\n",
    "import mysql.connector as mysql\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import boto3\n",
    "import threading\n",
    "import pika\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "menu_files = ['files','cluster_names', 'names']\n",
    "for menu_file in menu_files: \n",
    "    with open('./tmp/{mf}.txt'.format(mf=menu_file), 'w') as f: f.write('None')\n",
    "    \n",
    "# Widget styles\n",
    "style = {'description_width': 'initial'}\n",
    "features_layout = {'width': 'max-content','height':'200px'}\n",
    "\n",
    "# File selection menu\n",
    "ds_bucket = 'foresight-ds-docs'\n",
    "aws_access_key_id='AKIAQIALQA3XKOG2MNFS'\n",
    "aws_secret_access_key='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'\n",
    "s3 = boto3.resource('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "ds_bucket_obj = s3.Bucket(ds_bucket)\n",
    "matrices_dir = 'matrices'\n",
    "\n",
    "# Analyse button \n",
    "run_button = widgets.Button(description = \"Cluster\",style=style)\n",
    "run_button.style.button_color = 'lightgreen'\n",
    "# Metric menus\n",
    "metrics_layout = {'display':'flex','width': '130px','height':'30px', 'justify_content':'flex-end'}\n",
    "options = list(np.arange(1,11))\n",
    "options = [str(o) for o in options]\n",
    "metrics_optimize = {'min_max_tpc': ('min', 1), 'wcss': ('min', 1), 'bcss': ('max', 1), 'ch_index': ('max', 1),\\\n",
    "'db_index':('min', 1), 'silhouette':('max', 1), 'words_pairs': ('max', 1)}\n",
    "metrics = list(metrics_optimize.keys())\n",
    "metrics_menus = {}\n",
    "for metric in metrics:\n",
    "    menu=widgets.Dropdown(options=options,value='1',description=metric, layout=metrics_layout)\n",
    "    metrics_menus[metric]=menu\n",
    "# Granularity slider\n",
    "granularity = widgets.IntSlider(value=100, min=2, max=1000, step=1, description='Number of Clusters',\\\n",
    "                                     orientation='horizontal',readout=True, readout_format='d',\\\n",
    "                                     style = {'description_width': 'initial'}, layout=Layout(width='400px'))\n",
    "apply_granularity = widgets.ToggleButton(value=False, description='Select granularity level?',\n",
    "    disabled=False, button_style='info', tooltip='Description',\n",
    "    icon='check', layout=Layout(width='200px'))\n",
    "# Minimal cluster size\n",
    "min_cluster_menu=widgets.Dropdown(options=['0']+ options,value='0',\\\n",
    "                       description='Minimum number of tasks in cluster',\\\n",
    "                                   style = {'description_width': 'initial'},\\\n",
    "                                   layout=Layout(width='300px'))\n",
    "\n",
    "# Service    \n",
    "metrics_optimize = {'min_max_tpc': ('min', 1), 'wcss': ('min', 1), 'bcss': ('max', 1), 'ch_index': ('max', 1),\\\n",
    "'db_index':('min', 1), 'silhouette':('max', 1), 'words_pairs': ('max', 1)}\n",
    "db_name = 'CAdb'\n",
    "location_db_params = {'Local': {'host': 'localhost', 'user':'rony', 'password':'exp8546$fs', 'database': db_name},\\\n",
    "                      'Remote': {'host': '172.31.36.11', 'user':'researchUIuser', 'password':'query1234$fs', 'database': db_name}}\n",
    "location_url = {'Local': 'http://127.0.0.01:6002/cluster_analysis/api/v0.1/clustering',\\\n",
    "                'Remote': 'http://172.31.36.11/cluster_analysis/api/v0.1/clustering'}\n",
    "\n",
    "## Distance matrices\n",
    "distance_matrices = []\n",
    "matrices_paths = []\n",
    "# Distance matrices paths\n",
    "for object_summary in ds_bucket_obj.objects.filter(Prefix=matrices_dir):\n",
    "    file_key = object_summary.key\n",
    "    if file_key.split('/')[1]:\n",
    "        matrices_paths.append(file_key)\n",
    "# Load distance matrices\n",
    "for matrix_path in matrices_paths:\n",
    "    matrix_file = matrix_path.split('/')[1]\n",
    "    s3.Bucket(ds_bucket).download_file(matrix_path, matrix_file)\n",
    "    distance_matrices.append(pd.read_pickle(matrix_file))\n",
    "    os.remove(matrix_file)\n",
    "\n",
    "    \n",
    "from scipy.stats import zscore\n",
    "def x_outliers(x, threshold=3):\n",
    "\n",
    "    '''\n",
    "    Filter a list of values of outliers\n",
    "    :params:\n",
    "    x: A list of numeric values\n",
    "    threshold: The outliers cutoff\n",
    "    :return:\n",
    "    The filtered list\n",
    "    '''\n",
    "\n",
    "    x = pd.DataFrame(x, columns=['value'])\n",
    "    transformed = x[['value']].transform(zscore)\n",
    "    x['zscore'] = transformed\n",
    "    x_vals = x['value'][x['zscore'] <= threshold]\n",
    "    max_xvals = x_vals.max()\n",
    "    return max_xvals\n",
    "\n",
    "def histogram_stats(x, title, xtitle, fig_path=None):\n",
    "\n",
    "    '''\n",
    "    Plot histogram marking the mean, median and 3rd percentile values\n",
    "    and limit the x values range by outliers\n",
    "\n",
    "    :params:\n",
    "    x: A list or array of numeric values\n",
    "    title: The histogram title\n",
    "    xtitle: The counted values (x axis title)\n",
    "    fig_path: The path (directory and file name) to where the plot will be saved\n",
    "    :return: A saved histogram plot at the specified path\n",
    "    '''\n",
    "\n",
    "    result = plt.hist(x, bins=100, color='c', edgecolor='k', alpha=0.65)\n",
    "    min_ylim, max_ylim = plt.ylim()\n",
    "\n",
    "    # Add median line and value\n",
    "    median_x, mean_x = np.median(x), np.mean(x)\n",
    "    plt.axvline(median_x, color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.text(median_x * 1.1, max_ylim * 0.9, 'Median: {:.2f}'.format(median_x))\n",
    "\n",
    "    # Add 3rd quartile\n",
    "    plt.axvline(np.quantile(x, .75), color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.text(median_x * 1.1, max_ylim * 0.7, '3rd Quartile: {:.2f}'.format(np.quantile(x, .75)))\n",
    "\n",
    "    #Add mean line and value\n",
    "    plt.axvline(mean_x, color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.text(mean_x * 1.1, max_ylim * 0.5, 'Mean: {:.2f}'.format(mean_x))\n",
    "\n",
    "    x = list(x)\n",
    "    max_xlim = x_outliers(x)\n",
    "    plt.xlim(0, max_xlim)\n",
    "    plt.xlabel(xtitle)\n",
    "    plt.title(title)\n",
    "    if fig_path: plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "     \n",
    "## Cluster naming\n",
    "from nltk.corpus import stopwords\n",
    "punctuation_marks=\"=|\\+|_|\\.|:|\\/|\\*|\\'|,|\\?\"\n",
    "def isfloat(value):\n",
    "    '''\n",
    "    Check if the input value type is float\n",
    "    '''\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def isint(value):\n",
    "    '''\n",
    "    Check if the input value type is integer\n",
    "    '''\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def split_tokens (tokens, splitter):\n",
    "    tokens_splitter= [t for t in tokens if splitter in t]\n",
    "    tokens = [t for t in tokens if splitter not in t]\n",
    "    for t in tokens_splitter: tokens += t.split(splitter)\n",
    "    return tokens\n",
    "\n",
    "def tokens_count(tokens):\n",
    "    counts = dict()\n",
    "    for token in tokens:\n",
    "        if token in counts:\n",
    "            counts[token] += 1\n",
    "        else:\n",
    "            counts[token] = 1\n",
    "    return counts\n",
    "\n",
    "def normalize(text, punctuation_marks=punctuation_marks):\n",
    "    '''\n",
    "    Identify texts in tokens by the presence of symbols\n",
    "    '''\n",
    "    text = text.replace('&amp','')\n",
    "    tokens = text.split(' ')\n",
    "    for token in tokens:\n",
    "        if re.findall('\\d', token):\n",
    "            if re.findall('[A-Za-z]', token):\n",
    "                text = text.replace(token, '<name>')\n",
    "            else:\n",
    "                text = text.replace(token, '<number>')\n",
    "        elif re.findall(punctuation_marks, token):\n",
    "            text = text.replace(token, '<name>')\n",
    "    text = text.replace('<name> <name>', '<name>').replace('<number> <number>', '<number>')\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize(text, unique=False, exclude_stopwords=False, exclude_chars=True,\\\n",
    "              split_backslah=True, split_hyphen=True, split_plus=True, exclude_parenthesis_terms=False,\\\n",
    "              clean_punctuation=False, exclude_numbers=False, exclude_digit_tokens=False, \\\n",
    "              punctuation_marks=punctuation_marks, stopwords=set(stopwords.words('english')),\\\n",
    "              normalized_entities=True):\n",
    "    if exclude_parenthesis_terms:\n",
    "        pattern= '\\(.+?\\)|\\w*\\d{1,}\\.*\\d{1,}\\w*|\\w+'\n",
    "        text= re.sub(text, '', pattern)\n",
    "\n",
    "    if normalized_entities:\n",
    "        text = normalize(text)\n",
    "        pattern = '\\<.+?\\>|\\w*\\d{1,}\\.*\\d{1,}\\w*|\\w+'\n",
    "        tokenizer = nltk.RegexpTokenizer(pattern)\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "    else:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    if split_backslah: tokens = split_tokens (tokens, '/')\n",
    "    if split_hyphen: tokens = split_tokens(tokens, '-')\n",
    "    if split_plus: tokens = split_tokens(tokens, '+')\n",
    "\n",
    "    if exclude_stopwords: tokens = [t for t in tokens if t not in stopwords]\n",
    "    if clean_punctuation: tokens = [re.sub(punctuation_marks, '', t) for t in tokens]\n",
    "    if exclude_chars:tokens = [t for t in tokens if len(t) > 1]\n",
    "    if exclude_numbers:\n",
    "        tokens = [t for t in tokens if (not(isint(t)))]\n",
    "        tokens = [t for t in tokens if (not(isfloat(t)))]\n",
    "    if exclude_digit_tokens: tokens = [t for t in tokens if not re.findall('\\d', t)]\n",
    "    # Unique tokens preserving the tokens order in the input text\n",
    "    if unique: tokens = sorted(set(tokens), key=tokens.index)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_tokens_locations(parts):\n",
    "    tokens_locations = defaultdict(list)\n",
    "    for part in parts:\n",
    "        tokens = tokenize(part, unique=True, exclude_stopwords=False, \\\n",
    "                          exclude_numbers=True, exclude_digit_tokens=True)\n",
    "        tokens_indices = [tokens.index(t) for t in tokens]\n",
    "        for token in tokens:\n",
    "            tokens_locations[token].append(tokens_indices[tokens.index(token)])\n",
    "    tokens_typical_locations = {}\n",
    "    for token, locations in tokens_locations.items():\n",
    "        token_typical_location = max(set(locations), key=locations.count)\n",
    "        tokens_typical_locations[token] = token_typical_location\n",
    "\n",
    "    return tokens_typical_locations\n",
    "\n",
    "#######\n",
    "def text_to_key(cluster_names, cutoff=0.4):\n",
    "    cluster_key = ''\n",
    "    names_tokens = {}\n",
    "    for name in cluster_names:\n",
    "        tokens = tokenize(name, unique=True, exclude_stopwords=False, \\\n",
    "                           exclude_numbers=True, exclude_digit_tokens=True)\n",
    "        names_tokens[name] = tokens\n",
    "    #print('names_tokens:', names_tokens)\n",
    "    cluster_names_pairs = tuple(combinations(cluster_names, 2))\n",
    "    pairs_matches = []\n",
    "    for name_pair in cluster_names_pairs:\n",
    "        name1, name2 = name_pair\n",
    "        tokens1, tokens2 = names_tokens[name1], names_tokens[name2]\n",
    "        tokens1 = [t.lower() for t in tokens1]\n",
    "        tokens2 = [t.lower() for t in tokens2]\n",
    "        if name1 == name2:\n",
    "            pair_matches = tokens1\n",
    "        else:\n",
    "            len1, len2 = len(tokens1), len(tokens2)\n",
    "            if len1 <= len2:\n",
    "                short_name_tokens, long_name_tokens = tokens1, tokens2\n",
    "            else: short_name_tokens, long_name_tokens = tokens2, tokens1\n",
    "            pair_matches = []\n",
    "            for short_name_token in short_name_tokens:\n",
    "                short_name_token = [short_name_token]\n",
    "                names_token_pairs = list(itertools.product(short_name_token, long_name_tokens))\n",
    "                token_pairs_scores = {}\n",
    "                for tokens_pair in names_token_pairs:\n",
    "                    # Use distance matrices to score token pairs\n",
    "                    token1, token2 = tokens_pair\n",
    "                    token_pairs_score = 0\n",
    "                    for index, matrix in enumerate(distance_matrices):\n",
    "                        if all(x in matrix.columns for x in tokens_pair):\n",
    "                            matrix_score = matrix.at[token1, token2]\n",
    "                        else: matrix_score = 0\n",
    "                        token_pairs_score += matrix_score\n",
    "                    token_pairs_score = round(token_pairs_score, 2)\n",
    "                    token_pairs_scores[tokens_pair] = token_pairs_score\n",
    "\n",
    "                # Identify the best match in the long name to the short name token\n",
    "                max_score = max(list(token_pairs_scores.values()))\n",
    "                if max_score >= cutoff:\n",
    "                    for tokens_pair, pair_score in token_pairs_scores.items():\n",
    "                        if pair_score == max_score: matched_token = tokens_pair[1]\n",
    "                    #print('matched token with best score:', matched_token)\n",
    "                    pair_matches.append(matched_token)\n",
    "\n",
    "        pairs_matches.append(tuple(pair_matches))\n",
    "    matches_tokens = []\n",
    "    for pair_matches in pairs_matches: matches_tokens += list(pair_matches)\n",
    "    matches_tokens_counts = tokens_count(matches_tokens)\n",
    "\n",
    "    # Score each match by the frequency of its tokens\n",
    "    match_scores = {}\n",
    "    for pair_matches in pairs_matches:\n",
    "        match_score = 0\n",
    "        for token in pair_matches:\n",
    "            match_score += matches_tokens_counts[token]\n",
    "        match_scores[pair_matches] = match_score\n",
    "\n",
    "    # Score each match by it's length in relation to the cluster_key lengths\n",
    "    names = []\n",
    "    for name_pair in cluster_names_pairs: names += name_pair\n",
    "    names_lengths_median = np.median(np.array([len(name) for name in names]))\n",
    "    for pair_matches in pairs_matches:\n",
    "        if names_lengths_median>0:\n",
    "            near_median_factor = len(pair_matches)/names_lengths_median\n",
    "            match_scores[pair_matches] = near_median_factor * match_scores[pair_matches]\n",
    "        else: match_scores[pair_matches] = 0\n",
    "    # Identify the best scoring match\n",
    "    max_score = max(list(match_scores.values()))\n",
    "    for pair_matches, match_score in match_scores.items():\n",
    "        if match_score == max_score:\n",
    "            cluster_key = pair_matches\n",
    "\n",
    "    cluster_key = ' '.join(list(set(cluster_key)))\n",
    "    return cluster_key\n",
    "\n",
    "\n",
    "def parts_to_texts(cluster_names):\n",
    "    '''\n",
    "    Split a group of using a splitter symbol (e.g. hyphen) to produce lists of the phrase parts\n",
    "    Splitter: ' - '\n",
    "    '''\n",
    "    # Store names parts by their location relative to a hyphen break in each name\n",
    "    names_parts = defaultdict(list)\n",
    "    for name in cluster_names:\n",
    "        delimiters = ' - |/|\\(|\\)|\\[|\\]' # To keep parenthesis use ' - |/|,(\\(.+?\\))'\n",
    "        name_split = [i.rstrip().lstrip() for i in re.split(delimiters, name) if i]\n",
    "\n",
    "        # Number of parts produced by a hyphen break\n",
    "        num_parts = len(name_split)\n",
    "        parts_indices = np.arange(num_parts)\n",
    "        for index in parts_indices:\n",
    "            names_parts[index].append(name_split[index])\n",
    "    names_parts = dict(names_parts)\n",
    "    key_parts = ['']\n",
    "    for index, names_part in names_parts.items():\n",
    "        if len(names_part) > 1:\n",
    "            # Get key by the name part\n",
    "            parts_key = text_to_key(names_part, cutoff=0.8)\n",
    "            if parts_key:\n",
    "                part_key_tokens = tokenize(parts_key, unique=True, exclude_stopwords=False, \\\n",
    "                                           exclude_numbers=True, exclude_digit_tokens=True)\n",
    "                # Re-order the key words by their typical order in the name parts\n",
    "                tokens_typical_locations = get_tokens_locations(names_part)\n",
    "                key_tokens_locations = {k: v for k, v in tokens_typical_locations.items() if k in part_key_tokens}\n",
    "                sorted_key_tokens_locations = {k: v for k, v in sorted(key_tokens_locations.items(), key=lambda item: item[1])}\n",
    "                parts_key = ' '.join(list(sorted_key_tokens_locations.keys()))\n",
    "                parts_key = string.capwords(parts_key)\n",
    "                key_parts.append(parts_key)\n",
    "    key_parts = [i for i in key_parts if i]\n",
    "    if not key_parts:\n",
    "        if normalize(cluster_names[0]):\n",
    "            key_parts = [normalize(cluster_names[0])]\n",
    "    entity_labels = ['<number><name>', '<name><number>', '<name>', '<number>']\n",
    "    key_parts1 = []\n",
    "    for key_part in key_parts:\n",
    "        key_part = key_part.replace('> <', '><')\n",
    "        # Clear entity or number tags if they open a name part\n",
    "        for label in entity_labels:\n",
    "            label_pattern = '^\\s*{p}*\\s*{l}+'.format(l=label, p=punctuation_marks)\n",
    "            if re.findall(label_pattern, key_part):\n",
    "                key_part = re.sub(label_pattern, '', key_part)\n",
    "                key_part = key_part.lstrip().rstrip()\n",
    "        key_parts1.append(key_part)\n",
    "    key_parts1 = [p for p in key_parts1 if p]\n",
    "    key = ' - '.join(key_parts1)\n",
    "    key = key.replace('&amp', '')\n",
    "    key = re.sub('/|,|;', '-', key)\n",
    "\n",
    "    key = re.sub('^[\\s|{p}|-]*'.format(p=punctuation_marks), '', key)\n",
    "    key = key.lstrip('-')\n",
    "    if not key.rstrip().lstrip(): key = cluster_names[0]\n",
    "    return key\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "exchange = 'kc.ca.exchange'\n",
    "def get_results(experiment_id, conn):\n",
    "    def print_message(channel, method, properties, body):\n",
    "        message = json.loads(body)\n",
    "        run_cols = ['run_start', 'run_end', 'duration', 'tasks_count']\n",
    "        print('The clusters for the best run are ready for drill down analysis')\n",
    "        # Show runs results\n",
    "        display(HTML('<h1 style=\"color:magenta\">Run Scores </h1>'))\n",
    "        print('Run for experiment {id}'.format(id=experiment_id))\n",
    "        runs_df = pd.read_sql_query(\"SELECT * FROM runs \\\n",
    "        WHERE experiment_id={eid}\".format(eid=experiment_id), conn).drop(run_cols, axis=1)\n",
    "        display(runs_df)\n",
    "        channel.queue_delete(queue=queue)\n",
    "\n",
    "    queue ='experiment_{id}'.format(id=experiment_id)\n",
    "    # Consumer\n",
    "    credentials = pika.PlainCredentials('rnd', 'Rnd@2143')\n",
    "    parameters = pika.ConnectionParameters('172.31.34.107', 5672, '/', credentials)\n",
    "    connection = pika.BlockingConnection(parameters)\n",
    "    channel = connection.channel()\n",
    "    channel.queue_declare(queue=queue, auto_delete=False)\n",
    "    channel.exchange_declare(exchange=exchange, durable=True, exchange_type='direct')\n",
    "    channel.basic_consume(queue, print_message, auto_ack=True)\n",
    "    t1 = threading.Thread(target=channel.start_consuming)\n",
    "    t1.start()\n",
    "    t1.join(0)\n",
    "\n",
    "data_path = './data/experiments'\n",
    "def run_service(b):\n",
    "    service_location = service_button.value\n",
    "    file_source = file_source_button.value\n",
    "    print('service location:', service_location)\n",
    "    print('file source location:', file_source)\n",
    "    conn_params = location_db_params[service_location]\n",
    "    conn = mysql.connect(**conn_params)\n",
    "    c=conn.cursor()\n",
    "    c.execute(\"SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED\")\n",
    "    url = location_url[service_location]\n",
    "    file_checkpoints = True\n",
    "    ## Submitted data files\n",
    "    files = file_dd.value\n",
    "    num_files = len(files)\n",
    "    print('{n} files submitted:'.format(n=num_files), (',').join(list(files)).rstrip(','))\n",
    "    file_types = list(set([t.split('.')[1] for t in files]))\n",
    "    #Checkpoint: Files submitted\n",
    "    if files[0][0] == ' ':\n",
    "        print('No file selected')\n",
    "        file_checkpoints = False\n",
    "    #Checkpoint: Zip files\n",
    "    elif 'zip' in file_types:\n",
    "        print('zip in file types')\n",
    "        #Checkpoint: One among few files zipped \n",
    "        if num_files==1:\n",
    "            file = files[0]\n",
    "            tmp_file_path = os.path.join('./tmp', file) \n",
    "            file_path = os.path.join(data_path, file)\n",
    "            if file_source == 'Local':\n",
    "                shutil.copy2(file_path, tmp_file_path)\n",
    "                files = {'file': open(tmp_file_path, 'rb')} \n",
    "            else:\n",
    "                s3.Bucket(ds_bucket).download_file(file, tmp_file_path)\n",
    "                files = {'file': open(file_path, 'rb')}                \n",
    "        elif num_files>1:\n",
    "            print('The submitted files include a zip file')\n",
    "            file_checkpoints = False\n",
    "    \n",
    "    #Zip the data files \n",
    "    else:\n",
    "        file_paths = []\n",
    "        for file in files:\n",
    "            tmp_file_path = os.path.join('./tmp', file)\n",
    "            file_paths.append(tmp_file_path)\n",
    "            if file_source == 'Local':\n",
    "                file_path = os.path.join(data_path, file)\n",
    "                shutil.copy2(file_path, tmp_file_path) \n",
    "            else:\n",
    "                s3.Bucket(ds_bucket).download_file(file, tmp_file_path)\n",
    "        with ZipFile('zipped_files.zip','w') as zip:\n",
    "            # writing each file one by one\n",
    "            for file_path in file_paths:\n",
    "                zip.write(file_path)\n",
    "        files = {'file': open('zipped_files.zip', 'rb')}\n",
    "        os.remove('zipped_files.zip')\n",
    "    \n",
    "    if file_checkpoints:\n",
    "        ## Experiment configuration\n",
    "        config = {}\n",
    "        config['client'] = 'ui'\n",
    "        # Experiment id\n",
    "        experiment_ids = pd.read_sql_query(\"SELECT experiment_id from experiments\", conn).astype(int)\n",
    "        if len(experiment_ids) == 0: experiment_id = 1\n",
    "        else: experiment_id = int(max(experiment_ids.values)[0]) + 1\n",
    "        \n",
    "        config['service_location'] = service_location\n",
    "        config['experiment_id'] = experiment_id\n",
    "        print('experiment_id:', experiment_id)\n",
    "        \n",
    "        min_cluster_size = min_cluster_menu.value[0]\n",
    "        print('min_cluster_size:', min_cluster_size)\n",
    "        config['min_cluster_size'] = min_cluster_size\n",
    "\n",
    "        # Metrics weights\n",
    "        for metric, menu in metrics_menus.items():\n",
    "            config[metric] = menu.value[0]\n",
    "        if apply_granularity.value:\n",
    "            config['num_clusters'] = granularity.value\n",
    "        \n",
    "        # Post experiment data and configuration\n",
    "        response = requests.post(url, files=files, data=config)\n",
    "        print(response.text)\n",
    "        if response.text == 'Running clustering pipeline': \n",
    "            get_results(experiment_id, conn)\n",
    "           \n",
    "def left_align(df):\n",
    "    left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "    left_aligned_df = left_aligned_df.set_table_styles(\n",
    "        [dict(selector='th', props=[('text-align', 'left')])]\n",
    "    )\n",
    "    return left_aligned_df\n",
    "\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:right\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h2>{title}</h2>'\n",
    "        df=left_align(df)\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Files and Service Location</h1>                 <ul>                  <li style=\"color:blue\">The service runs remotely by default</li>                  <li style=\"color:blue\">Remote files are files located on AWS</li>                  <li style=\"color:blue\">To use local files store them in ./data/experiment</li>                </ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90a1e0f701d4cdf9a6edc2fabf82987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='File Source:', layout=Layout(width='max-content'), options=('Local', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_files_list(b): \n",
    "    data_files = [' ']\n",
    "    if file_source_button.value == 'Local':\n",
    "        data_files += os.listdir(data_path)\n",
    "    else:\n",
    "        for key in s3_client.list_objects(Bucket=ds_bucket)['Contents']:\n",
    "            data_files.append(key['Key'])\n",
    "    data_files = '\\n'.join(data_files)\n",
    "    with open(os.path.join('./tmp', 'files.txt'), 'w') as f: f.write(data_files)\n",
    "\n",
    "display(HTML('<h1 style=\"color:magenta\">Files and Service Location</h1>\\\n",
    "                 <ul>\\\n",
    "                  <li style=\"color:blue\">The service runs remotely by default</li>\\\n",
    "                  <li style=\"color:blue\">Remote files are files located on AWS</li>\\\n",
    "                  <li style=\"color:blue\">To use local files store them in ./data/experiment</li>\\\n",
    "                </ul>'))\n",
    "file_source_button = widgets.RadioButtons(\n",
    "    options=['Local', 'Remote'], value='Local',layout={'width': 'max-content'}, description='File Source:',\n",
    "    disabled=False)\n",
    "service_button = widgets.RadioButtons(\n",
    "    options=['Local', 'Remote'], value='Remote',layout={'width': 'max-content'}, description='Service:',\n",
    "    disabled=False)\n",
    "location_button = widgets.Button(description = \"Set Locations\",style=style, layout={'width': 'max-content'})\n",
    "location_button.style.button_color = 'lightgreen'\n",
    "location_button.on_click(build_files_list)\n",
    "HBox(children=[file_source_button, service_button, location_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Cluster Activities</h1>              <p style=\"color:blue\">Use to following menus to submit a file for analysis:</p>                 <ul>                  <li style=\"color:magenta\">File to analyze</li>                  <li style=\"color:magenta\">Select granularity level</li>                  <li style=\"color:magenta\">Set weights for validation metrics</li>                </ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b9d17081144ff09478b280bc8855da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(SelectMultiple(description='File:', index=(0, 0), layout=Layout(height='200px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service location: Local\n",
      "file source location: Local\n",
      "1 files submitted: CCGTD1_IPS.xer\n",
      "experiment_id: 59\n",
      "min_cluster_size: 0\n",
      "Running clustering pipeline\n",
      "The clusters for the best run are ready for drill down analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Run Scores </h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run for experiment 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>num_files</th>\n",
       "      <th>language_model</th>\n",
       "      <th>clustering_method</th>\n",
       "      <th>clustering_params</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>mean_duration_std</th>\n",
       "      <th>tasks_per_cluster_mean</th>\n",
       "      <th>tasks_per_cluster_median</th>\n",
       "      <th>min_tasks_per_cluster</th>\n",
       "      <th>max_tasks_per_cluster</th>\n",
       "      <th>min_max_tpc</th>\n",
       "      <th>wcss</th>\n",
       "      <th>bcss</th>\n",
       "      <th>ch_index</th>\n",
       "      <th>db_index</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>words_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>90</td>\n",
       "      <td>24.41</td>\n",
       "      <td>40.2</td>\n",
       "      <td>36.5</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "      <td>1534.86</td>\n",
       "      <td>1566.79</td>\n",
       "      <td>40.47</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>180</td>\n",
       "      <td>20.93</td>\n",
       "      <td>20.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>1212.7</td>\n",
       "      <td>1888.93</td>\n",
       "      <td>29.92</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.3</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>271</td>\n",
       "      <td>20.31</td>\n",
       "      <td>13.35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>1012.42</td>\n",
       "      <td>2089.23</td>\n",
       "      <td>25.58</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.34</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>361</td>\n",
       "      <td>18.89</td>\n",
       "      <td>10.02</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>868.77</td>\n",
       "      <td>2232.85</td>\n",
       "      <td>23.25</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>452</td>\n",
       "      <td>17.84</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>753.35</td>\n",
       "      <td>2348.22</td>\n",
       "      <td>21.88</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.4</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>542</td>\n",
       "      <td>17.08</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>656.5</td>\n",
       "      <td>2445.08</td>\n",
       "      <td>21.18</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>633</td>\n",
       "      <td>16.59</td>\n",
       "      <td>5.72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>575.17</td>\n",
       "      <td>2526.47</td>\n",
       "      <td>20.75</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>CCGTD1_IPS</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>affinity|euclidean</td>\n",
       "      <td>723</td>\n",
       "      <td>15.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>506.36</td>\n",
       "      <td>2595.24</td>\n",
       "      <td>20.55</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id run_id   file_name num_files    language_model  \\\n",
       "0            59      1  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "1            59      2  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "2            59      3  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "3            59      4  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "4            59      5  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "5            59      6  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "6            59      7  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "7            59      8  CCGTD1_IPS         1  all-MiniLM-L6-v2   \n",
       "\n",
       "         clustering_method   clustering_params num_clusters mean_duration_std  \\\n",
       "0  AgglomerativeClustering  affinity|euclidean           90             24.41   \n",
       "1  AgglomerativeClustering  affinity|euclidean          180             20.93   \n",
       "2  AgglomerativeClustering  affinity|euclidean          271             20.31   \n",
       "3  AgglomerativeClustering  affinity|euclidean          361             18.89   \n",
       "4  AgglomerativeClustering  affinity|euclidean          452             17.84   \n",
       "5  AgglomerativeClustering  affinity|euclidean          542             17.08   \n",
       "6  AgglomerativeClustering  affinity|euclidean          633             16.59   \n",
       "7  AgglomerativeClustering  affinity|euclidean          723             15.04   \n",
       "\n",
       "  tasks_per_cluster_mean tasks_per_cluster_median min_tasks_per_cluster  \\\n",
       "0                   40.2                     36.5                     6   \n",
       "1                   20.1                     16.0                     5   \n",
       "2                  13.35                     10.0                     3   \n",
       "3                  10.02                      8.0                     2   \n",
       "4                    8.0                      6.0                     2   \n",
       "5                   6.68                      5.0                     2   \n",
       "6                   5.72                      4.0                     1   \n",
       "7                    5.0                      4.0                     1   \n",
       "\n",
       "  max_tasks_per_cluster min_max_tpc     wcss     bcss ch_index db_index  \\\n",
       "0                   127         121  1534.86  1566.79    40.47     2.37   \n",
       "1                    85          80   1212.7  1888.93    29.92     2.02   \n",
       "2                    78          75  1012.42  2089.23    25.58     1.84   \n",
       "3                    78          76   868.77  2232.85    23.25     1.68   \n",
       "4                    78          76   753.35  2348.22    21.88     1.52   \n",
       "5                    78          76    656.5  2445.08    21.18     1.42   \n",
       "6                    78          77   575.17  2526.47    20.75     1.32   \n",
       "7                    78          77   506.36  2595.24    20.55     1.21   \n",
       "\n",
       "  silhouette words_pairs  \n",
       "0       0.24          86  \n",
       "1        0.3         175  \n",
       "2       0.34         271  \n",
       "3       0.37         368  \n",
       "4        0.4         466  \n",
       "5       0.42         564  \n",
       "6       0.43         662  \n",
       "7       0.45         759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dashboard\n",
    "run_button.on_click(run_service)\n",
    "display(HTML('<h1 style=\"color:magenta\">Cluster Activities</h1>\\\n",
    "              <p style=\"color:blue\">Use to following menus to submit a file for analysis:</p>\\\n",
    "                 <ul>\\\n",
    "                  <li style=\"color:magenta\">File to analyze</li>\\\n",
    "                  <li style=\"color:magenta\">Select granularity level</li>\\\n",
    "                  <li style=\"color:magenta\">Set weights for validation metrics</li>\\\n",
    "                </ul>'))\n",
    "data_files = [i for i in ([' '] + open('./tmp/files.txt').read().split('\\n')) if i]\n",
    "default = (data_files[0], ' ')\n",
    "file_dd=widgets.SelectMultiple(options=data_files,value=default,\n",
    "    description='File:',style=style,layout=features_layout)\n",
    "file_box = VBox(children=[file_dd, run_button])\n",
    "metrics_box = VBox(children=list(metrics_menus.values()))\n",
    "config_box = VBox(children=[apply_granularity, granularity, min_cluster_menu])\n",
    "HBox(children=[file_box, config_box, metrics_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Results</h1>'"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961dba79aa8b4ee6beb5909d5c5fb355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Experiment:', layout=Layout(width='max-content'), options=(1, 2, 3, 4, 5,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 file submitted: CCGTD1_IPS\n",
      "\n",
      "3618 task dependent activities clustered\n",
      "0 duplicate tasks removed prior to the analysis\n",
      "The best run(rid) produced 633 Clusters\n",
      "The clusters contain between 1 and 78 tasks,0 of them orphans,    \n",
      "with an average of 5.7 and a median of 4 tasks per cluster.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def revise_key(collected_clusters):\n",
    "    clusters = {}\n",
    "    for cluster_key, cluster_members in collected_clusters.items():\n",
    "        num_tasks = len(cluster_members)\n",
    "        revised_key = '{k} ({n})'.format(k=cluster_key, n=str(num_tasks))\n",
    "        clusters[revised_key] = cluster_members\n",
    "    return clusters\n",
    "\n",
    "def result_from_table(experiment_id, result_key='clusters'):\n",
    "    result_df = pd.read_sql_query(\"SELECT * FROM results \\\n",
    "    WHERE experiment_id={eid}\".format(eid=experiment_id), conn)\n",
    "    result = result_df['result'].values[0]\n",
    "    result = ast.literal_eval(result)\n",
    "    return result[result_key]\n",
    "\n",
    "def tasks_per_cluster_counts(experiment_id):\n",
    "    tasks_per_clusters = []\n",
    "    result = result_from_table(experiment_id)\n",
    "    cluster_keys = list(result.keys())\n",
    "    for cluster_key in cluster_keys:\n",
    "        num_tasks = len(result[cluster_key])\n",
    "        #print(cluster_key, num_tasks)\n",
    "        tasks_per_clusters.append(num_tasks)\n",
    "    return np.array(tasks_per_clusters)\n",
    "\n",
    "def get_clusters(b):\n",
    "    experiment_id = experiments_dd.value\n",
    "    \n",
    "    result_df = pd.read_sql_query(\"SELECT * FROM results \\\n",
    "    WHERE experiment_id={eid}\".format(eid=experiment_id), conn)\n",
    "    best_run_id = result_df['run_id'].values[0]\n",
    "    num_clusters = result_df['num_clusters'].values[0]\n",
    "    tasks_count = result_df['tasks_count'].values[0]\n",
    "    task_duplicates_count = planned_duration_dict = result_from_table(experiment_id, 'duplicates_count') \n",
    "    tasks_per_cluster_mean = result_df['tasks_per_cluster_mean'].values[0]\n",
    "    tasks_per_cluster_median = str(int(float(result_df['tasks_per_cluster_median'].values[0])))\n",
    "    min_tasks_per_cluster = result_df['min_tasks_per_cluster'].values[0]\n",
    "    max_tasks_per_cluster = result_df['max_tasks_per_cluster'].values[0]\n",
    "    data_files = result_df['file_name'].values[0].replace('*', ', ')\n",
    "    data_files_count = result_df['num_files'].values[0]\n",
    "    file_names = result_df['file_name'].values[0]\n",
    "    if int(data_files_count)==1: print_statement = '1 file submitted:'\n",
    "    else: print_statement = '{n} files submitted:'.format(n=data_files_count)\n",
    "    tasks_per_cluster = tasks_per_cluster_counts(experiment_id)\n",
    "    orphans_count = len([i for i in tasks_per_cluster if i==1])\n",
    "    print(print_statement, data_files)\n",
    "    print()\n",
    "    print('{n} task dependent activities clustered'.format(n=tasks_count))\n",
    "    print('{n} duplicate tasks removed prior to the analysis'.format(n=str(task_duplicates_count)))\n",
    "    print('The best run(rid) produced {n} Clusters'.format(rid=best_run_id, n=str(num_clusters)))\n",
    "    print('The clusters contain between {min} and {max} tasks,{no} of them orphans,\\\n",
    "    \\nwith an average of {m1} and a median of {m2} tasks per cluster.'.format(min=min_tasks_per_cluster, max=max_tasks_per_cluster,\\\n",
    "           m1=round(float(tasks_per_cluster_mean),1), m2=tasks_per_cluster_median, no=orphans_count))\n",
    "    \n",
    "    histogram_stats(tasks_per_cluster, 'Tasks per Cluster', 'Number of Tasks')\n",
    "    \n",
    "    collected_clusters = result_from_table(experiment_id)\n",
    "    clusters = revise_key(collected_clusters)\n",
    "    \n",
    "    sort_by = clusters_sort_dd.value\n",
    "    # Sort clusters by number of tasks per cluster\n",
    "    if tasks_num_dd.value != 'All':\n",
    "        min_max_tasks = tasks_vals_nums[tasks_num_dd.value]\n",
    "        min_tasks = min_max_tasks[0]\n",
    "        clusters = {k:v for k,v in clusters.items() if len(v)>=min_tasks}\n",
    "        if len(min_max_tasks)==2:\n",
    "            clusters = {k:v for k,v in clusters.items() if len(v)<5}\n",
    "    \n",
    "    clusters_keys = list(clusters.keys())\n",
    "    if sort_by == 'Alphabetic Order':\n",
    "        clusters_keys.sort()\n",
    "    elif sort_by == 'Tasks per Cluster':\n",
    "        clusters_num_tasks = {}\n",
    "        for cluster_key in clusters_keys: clusters_num_tasks[cluster_key]=len(clusters[cluster_key])\n",
    "        clusters = {k: v for k, v in sorted(clusters_num_tasks.items(),\\\n",
    "                    key=lambda item: item[1], reverse=True)}\n",
    "        clusters_keys = list(clusters.keys())\n",
    "    else:\n",
    "        # Calculate %Overrun for sorting\n",
    "        planned_duration_dict = result_from_table(experiment_id, 'planned_duration_vals') \n",
    "        actual_duration_dict = result_from_table(experiment_id, 'actual_duration_vals') \n",
    "        clusters_overruns = {}\n",
    "        for cluster_key in clusters_keys:\n",
    "            ids_names = clusters[cluster_key]\n",
    "            cluster_ids = [i[0] for i in ids_names]\n",
    "            cluster_planned_duration_dict = {k:v for k,v in planned_duration_dict.items() if k in cluster_ids}\n",
    "            cluster_actual_duration_dict = {k:v for k,v in actual_duration_dict.items() if k in cluster_ids}\n",
    "            planned_in_actual_dict = {k:v for k,v in cluster_planned_duration_dict.items()\\\n",
    "                                      if k in cluster_actual_duration_dict.keys()}\n",
    "            tasks_overrun_perc = []\n",
    "            for id, task_planned_duration in planned_in_actual_dict.items():\n",
    "                task_actual_duration = actual_duration_dict[id]\n",
    "                if task_planned_duration != 0:\n",
    "                    task_overrun_perc = 100*((task_actual_duration/task_planned_duration)-1)\n",
    "                    tasks_overrun_perc.append(task_overrun_perc)\n",
    "            if tasks_overrun_perc:\n",
    "                mean_perc_overrun = round(int(np.mean(tasks_overrun_perc)), 2)\n",
    "            else: mean_perc_overrun = 0\n",
    "            clusters_overruns[cluster_key] = mean_perc_overrun    \n",
    "        clusters_overruns = {k: v for k, v in sorted(clusters_overruns.items(),\\\n",
    "                                                     key=lambda item: item[1], reverse=True)}\n",
    "        clusters_keys = list(clusters_overruns.keys())\n",
    "    clusters_keys = '\\n'.join(clusters_keys)\n",
    "    with open('./tmp/cluster_names.txt', 'w') as f: f.write(clusters_keys)\n",
    "\n",
    " \n",
    "service_location = service_button.value\n",
    "conn_params = location_db_params[service_location]\n",
    "conn = mysql.connect(**conn_params)\n",
    "display(HTML('<h1 style=\"color:magenta\">Results</h1>\\''))\n",
    "experiment_ids = pd.read_sql_query(\"SELECT experiment_id FROM experiments\", conn).astype(int)\n",
    "experiment_ids = list(experiment_ids['experiment_id'].unique())\n",
    "if len(experiment_ids) == 0: experiment_ids = ['None']\n",
    "experiments_dd=widgets.Dropdown(options=experiment_ids, value=experiment_ids[0],\n",
    "    description='Experiment:',style=style, layout={'width': 'max-content'})\n",
    "sort_options = ['Alphabetic Order', 'Percent Overrun Mean Percentage', 'Tasks per Cluster']\n",
    "clusters_sort_dd=widgets.Dropdown(options=sort_options, value=sort_options[0],\n",
    "    description='Sort By (Desc):',style=style, layout={'width': 'max-content'})\n",
    "tasks_vals_nums = {'1':(1,), '2 to 5':(2,5),\\\n",
    "                   '5 and above':(5,), '10 and above':(10,),'20 and above':(20,)}\n",
    "cluster_nums_options = ['All'] + list(tasks_vals_nums.keys())\n",
    "tasks_num_dd=widgets.Dropdown(options=cluster_nums_options, value=cluster_nums_options[0],\n",
    "    description='Tasks in Cluster:',style=style, layout={'width': 'max-content'})\n",
    "\n",
    "clusters_button = widgets.Button(description = \"Clusters \",style=style, layout={'width': 'max-content'})\n",
    "clusters_button.style.button_color = 'lightblue'\n",
    "clusters_button.on_click(get_clusters)\n",
    "HBox(children=[experiments_dd, tasks_num_dd, clusters_sort_dd, clusters_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Select Cluster</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5951c9034f74479caaa58a4cc1d7d388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(layout=Layout(width='80%'), options=('Ac - Dc Installation (6)', 'Actuators All For (2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select cluster: And Temporary Works For Shaft - Resubmission Of Temp Works For Shaft - Els (4)\n"
     ]
    }
   ],
   "source": [
    "def get_tasks(b):\n",
    "    experiment_id = experiments_dd.value\n",
    "    ids_files = result_from_table(experiment_id, 'ids_files')\n",
    "    collected_clusters = result_from_table(experiment_id)\n",
    "    clusters = revise_key(collected_clusters)\n",
    "    cluster_key = clusters_keys_dd.value\n",
    "    print('Select cluster:', cluster_key)\n",
    "    ids_names = clusters[cluster_key]\n",
    "    ids_names = [[ids_files[id_name[0]].replace('tmp/', '').replace('.xer','')[:8]]+id_name for id_name in ids_names]\n",
    "    ids_names = [' '.join(id_name) for id_name in ids_names]\n",
    "    ids_names = '\\n'.join(ids_names)\n",
    "    with open('./tmp/names.txt', 'w') as f: f.write(ids_names)\n",
    "        \n",
    "clusters_keys = open('./tmp/cluster_names.txt').read().split('\\n')\n",
    "clusters_keys_dd=widgets.Dropdown(options=clusters_keys, value=clusters_keys[0],\n",
    "    style=style, layout={'width': '80%'})\n",
    "\n",
    "tasks_button = widgets.Button(description = \"Tasks\",style=style, layout={'width': 'max-content'})\n",
    "tasks_button.style.button_color = 'orange'\n",
    "tasks_button.on_click(get_tasks)\n",
    "display(HTML('<h1 style=\"color:magenta\">Select Cluster</h1>'))\n",
    "VBox(children=[clusters_keys_dd, experiments_dd, tasks_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color:magenta\">Tasks to Exclude</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2315c5ebd04f42cf9d7c1121927beb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Experiment:', index=58, layout=Layout(width='max-content'), options=(1, 2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cluster_stats_plots(b):\n",
    "    cluster_key = clusters_keys_dd.value\n",
    "    experiment_id = experiments_dd.value\n",
    "    collected_clusters = result_from_table(experiment_id)\n",
    "    clusters = revise_key(collected_clusters)\n",
    "    \n",
    "    names_to_exclude = ids_names_dd.value\n",
    "    exclude_ids = [i.split(' ')[0] for i in names_to_exclude]\n",
    "    \n",
    "    # Activities duration values\n",
    "    ids_names = {i[0]:i[1] for i in clusters[cluster_key] if i[0] not in exclude_ids}\n",
    "    ids, names = list(ids_names.keys()), list(ids_names.values())\n",
    "    new_key = parts_to_texts(names)\n",
    "\n",
    "    planned_duration_dict = result_from_table(experiment_id, 'planned_duration_vals') \n",
    "    planned_duration_dict = {k:v for k,v in planned_duration_dict.items() if k in ids}\n",
    "    planned_duration_vals = list(planned_duration_dict.values())\n",
    "    \n",
    "    actual_duration_dict = result_from_table(experiment_id, 'actual_duration_vals') \n",
    "    actual_duration_dict = {k:v for k,v in actual_duration_dict.items() if k in ids}\n",
    "    actual_duration_vals = list(actual_duration_dict.values())\n",
    "    \n",
    "    tasks_overrun_perc = []\n",
    "    # Duration ratios and overruns\n",
    "    duration_ratios, tasks_overrun, tasks_overrun_perc = [], [], []\n",
    "    cluster_description_rows = []\n",
    "    for id, task_planned_duration in planned_duration_dict.items():\n",
    "        cluster_description_row = [id, ids_names[id], int(task_planned_duration)]\n",
    "        if id in actual_duration_dict.keys(): \n",
    "            task_actual_duration = actual_duration_dict[id]\n",
    "            cluster_description_row.append(int(task_actual_duration))\n",
    "            if task_planned_duration != 0:\n",
    "                duration_ratios.append(round(task_actual_duration/task_planned_duration,2))\n",
    "                task_overrun = task_actual_duration-task_planned_duration\n",
    "                tasks_overrun.append(task_overrun)\n",
    "                tasks_overrun_perc.append(100*((task_actual_duration/task_planned_duration)-1))\n",
    "        else:\n",
    "            cluster_description_row.append(None)\n",
    "        cluster_description_rows.append(cluster_description_row)\n",
    "\n",
    "    ## Cluster Statistics\n",
    "    display(HTML('<h1 style=\"color:magenta\">Cluster RCF Analysis</h1>'))\n",
    "    print('Key:', new_key)\n",
    "    print('Cluster Statistics')\n",
    "    print('Activities in Cluster:', len(ids))\n",
    "    print('Completed Activities in Cluster:', len(actual_duration_vals))\n",
    "    # Table\n",
    "    index = ['Planned Duration(Days)', 'Actual Duration(Days)', 'Overrun(Days)', 'Overrun(%)']\n",
    "    headers = ['MEAN', 'MEDIAN', 'STD']\n",
    "    def stats_row(arr): \n",
    "        if len(arr)>0:\n",
    "            return [np.mean(arr), np.median(arr), np.std(arr)]\n",
    "        else:\n",
    "            return(np.nan, np.nan, np.nan)\n",
    "    table_rows = [stats_row(planned_duration_vals), stats_row(actual_duration_vals),\\\n",
    "                 stats_row(tasks_overrun), stats_row(tasks_overrun_perc)]\n",
    "    stats_df = pd.DataFrame(table_rows, columns=headers, index=index)\n",
    "    stats_df = round(stats_df, 2)\n",
    "    #display(stats_df)                \n",
    "\n",
    "    # Plot Values: RCF for Tasks in Cluster\n",
    "    # x = percentile,  y = duration_ratios\n",
    "    duration_ratios.sort()\n",
    "    sum_ratios = sum(duration_ratios)\n",
    "    ratios_cumsum = np.cumsum(duration_ratios)\n",
    "    percentile = 100*(ratios_cumsum/sum_ratios)\n",
    "    rcf_df = pd.DataFrame(list(zip(percentile, duration_ratios)),\\\n",
    "                          columns = ['Percentile', 'Duration Ratio'])\n",
    "\n",
    "    # Plot Values: Duration Distribution\n",
    "    duration_type = len(planned_duration_vals) * ['Planned'] + len(actual_duration_vals) *['Actual']\n",
    "    duration_vals = list(planned_duration_vals)+list(actual_duration_vals)\n",
    "    duration_df = pd.DataFrame(list(zip(duration_type, duration_vals)), columns=['Duration', 'Days'])\n",
    "\n",
    "    # Cluster description\n",
    "    ids_files = result_from_table(experiment_id, 'ids_files')\n",
    "    names_duration_df = pd.DataFrame(cluster_description_rows,\\\n",
    "                        columns = ['ID', 'Name', 'Planned Duration', 'Actual Duration']).dropna()\n",
    "    task_source_files = [ids_files[id].replace('tmp/', '').replace('.xer','')[:8]\\\n",
    "                         for id in list(names_duration_df['ID'])]\n",
    "    names_duration_df['File'] = task_source_files\n",
    "    names_duration_df = names_duration_df[['ID', 'File', 'Name', 'Planned Duration', 'Actual Duration']]\n",
    "    #names_duration_df.to_excel('{k}.xlsx'.format(k=cluster_key), index=False)\n",
    "    ## Display\n",
    "    # Tables\n",
    "    display_side_by_side(names_duration_df,stats_df, titles=['Tasks in Cluster','Cluster Statistics'])\n",
    "\n",
    "    # Plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))#, sharey=True)\n",
    "    duration_dist = sns.boxplot(ax=axes[0], x=\"Duration\", y=\"Days\", data=duration_df)\n",
    "    rcf = sns.lineplot(ax=axes[1], x=\"Percentile\", y=\"Duration Ratio\", data=rcf_df)\n",
    "    axes[0].set_title('Duration Distibution (Tasks in Cluster)')\n",
    "    axes[1].set_title('RCF For Tasks in Cluster')\n",
    "\n",
    "\n",
    "ids_names = [' '] + open('./tmp/names.txt').read().split('\\n')\n",
    "layout={'width': 'max-content', 'height':'max-content'}\n",
    "rows_count = len(ids_names)\n",
    "if rows_count>20: rows_count = int(rows_count/2.5)   \n",
    "ids_names_dd=widgets.SelectMultiple(options=ids_names, value=(ids_names[0], ' '),\n",
    "style=style, layout=layout, rows = rows_count)\n",
    "button = widgets.Button(description = \"Run RCF\",style=style)\n",
    "button.style.button_color = 'yellow'\n",
    "button.on_click(cluster_stats_plots)\n",
    "display(HTML('<h1 style=\"color:magenta\">Tasks to Exclude</h1>'))\n",
    "VBox(children=[experiments_dd, ids_names_dd, button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
